{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19214eb1-91c7-479b-b9a4-80cf21618a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: opencv-python in c:\\users\\ben.magrathea\\.pyenv\\pyenv-win\\versions\\3.9.0\\lib\\site-packages (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\ben.magrathea\\.pyenv\\pyenv-win\\versions\\3.9.0\\lib\\site-packages (from opencv-python) (1.24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a73483-42a9-4255-a6da-deb51f19d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "class MotionRecognition:\n",
    "    def __init__(self):\n",
    "        self.sift = cv2.SIFT_create()\n",
    "        self.mhi_duration = 10\n",
    "        self.clf = svm.SVC()\n",
    "\n",
    "    def extract_sift_features(self, image):\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        keypoints, descriptors = self.sift.detectAndCompute(gray, None)\n",
    "        return keypoints, descriptors\n",
    "\n",
    "    def update_mhi(self, prev_frame, current_frame, mhi):\n",
    "        diff = cv2.absdiff(prev_frame, current_frame)\n",
    "        _, binary_diff = cv2.threshold(diff, 30, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "        timestamp = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "        mhi *= 0.9\n",
    "        mhi[binary_diff > 0] = timestamp\n",
    "\n",
    "        return mhi\n",
    "\n",
    "    def process_video(self):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        ret, prev_frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            raise ValueError(\"Cannot read the video file.\")\n",
    "\n",
    "        prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        mhi = np.zeros_like(prev_frame, dtype=np.float32)\n",
    "\n",
    "        while True:\n",
    "            ret, current_frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            current_frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "            mhi = self.update_mhi(prev_frame, current_frame_gray, mhi)\n",
    "\n",
    "            keypoints, descriptors = self.extract_sift_features(current_frame)\n",
    "            current_frame_with_keypoints = cv2.drawKeypoints(current_frame, keypoints, None)\n",
    "\n",
    "            cv2.imshow(\"Current Frame with SIFT keypoints\", current_frame_with_keypoints)\n",
    "            cv2.imshow(\"MHI\", mhi)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            prev_frame = current_frame_gray\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def train_svm(self, X_train, y_train):\n",
    "        self.clf.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.clf.predict(X_test)\n",
    "\n",
    "    def k_fold_cross_validation(self, X, y, n_splits=5):\n",
    "        kf = KFold(n_splits=n_splits)\n",
    "        scores = cross_val_score(self.clf, X, y, cv=kf)\n",
    "        return scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138aa142-f79d-4669-a4b5-6f21e2bdd6e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'data\\\\boxing\\\\person01_boxing_d1_uncomp.avi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mmean(), scores\u001b[39m.\u001b[39mstd()\n\u001b[0;32m     70\u001b[0m \u001b[39m# Load your training and testing data here\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m X_train, y_train, X_test, y_test \u001b[39m=\u001b[39m load_your_data()\n\u001b[0;32m     73\u001b[0m motion_recognition \u001b[39m=\u001b[39m MotionRecognition()\n\u001b[0;32m     75\u001b[0m \u001b[39m# Train the SVM classifier\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m, in \u001b[0;36mload_your_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m person \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(action_path):\n\u001b[0;32m     27\u001b[0m     person_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(action_path, person)\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mfor\u001b[39;00m video \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(person_path):\n\u001b[0;32m     29\u001b[0m         video_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(person_path, video)\n\u001b[0;32m     30\u001b[0m         cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(video_path)\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'data\\\\boxing\\\\person01_boxing_d1_uncomp.avi'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "motion_recognition = MotionRecognition()\n",
    "\n",
    "def process_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    features = []\n",
    "    ret, prev_frame = cap.read()\n",
    "    prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    mhi = np.zeros_like(prev_frame, dtype=np.float32)\n",
    "\n",
    "    while True:\n",
    "        ret, current_frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        current_frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "        mhi = motion_recognition.update_mhi(prev_frame, current_frame_gray, mhi)\n",
    "        keypoints, descriptors = motion_recognition.extract_sift_features(current_frame)\n",
    "        features.append(descriptors)\n",
    "        prev_frame = current_frame_gray\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return features, mhi\n",
    "\n",
    "def load_your_data(progress_interval=10):\n",
    "    sift = cv2.SIFT_create()\n",
    "    data_path = 'motions'\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    futures = []\n",
    "\n",
    "    action_map = {\n",
    "        'boxing': 0,\n",
    "        'handclapping': 1,\n",
    "        'handwaving': 2,\n",
    "        'jogging': 3,\n",
    "        'running': 4,\n",
    "        'walking': 5\n",
    "    }\n",
    "\n",
    "    total_videos = 0\n",
    "    for action in os.listdir(data_path):\n",
    "        if action not in action_map:\n",
    "            continue\n",
    "        action_path = os.path.join(data_path, action)\n",
    "        for video in os.listdir(action_path):\n",
    "            total_videos += 1\n",
    "\n",
    "    processed_videos = 0\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for action in os.listdir(data_path):\n",
    "            if action not in action_map:\n",
    "                continue\n",
    "            action_path = os.path.join(data_path, action)\n",
    "            for video in os.listdir(action_path):\n",
    "                video_path = os.path.join(action_path, video)\n",
    "                future = executor.submit(process_video, video_path)\n",
    "                futures.append((future, action_map[action]))\n",
    "\n",
    "        for future, action_label in futures:\n",
    "            features, _ = future.result()\n",
    "\n",
    "            if len(features) < 10:\n",
    "                # Discard videos that are too short\n",
    "                continue\n",
    "\n",
    "            # Split the video features into training and testing sets\n",
    "            split_index = int(len(features) * 0.8)\n",
    "            train_data.extend(features[:split_index])\n",
    "            test_data.extend(features[split_index:])\n",
    "            train_labels.extend([action_label] * split_index)\n",
    "            test_labels.extend([action_label] * (len(features) - split_index))\n",
    "\n",
    "            processed_videos += 1\n",
    "            if processed_videos % progress_interval == 0:\n",
    "                print(f\"Processed {processed_videos}/{total_videos} videos.\")\n",
    "\n",
    "    X_train = np.vstack(train_data)\n",
    "    y_train = np.array(train_labels)\n",
    "    X_test = np.vstack(test_data)\n",
    "    y_test = np.array(test_labels)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f2b8a-e15f-47ad-a0ea-35514a577ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
